import OpenAI from 'openai';
import { OPENAI_MODELS, MODEL_COSTS } from '../../shared/config/constants.js';
import { ErrorHandler } from '../utils/errorHandler.js';
import { Logger } from '../../shared/utils/logger.js';
import dotenv from 'dotenv';
dotenv.config();

/**
 * å“åº”æœåŠ¡ - å¤„ç†æ–‡ä»¶æœç´¢å’Œç½‘ç»œæœç´¢
 */
export class ResponseService {
	constructor() {
		this.client = new OpenAI({
			apiKey: process.env.OPENAI_API_KEY,
		});
	}

	/**
	 * æŸ¥è¯¢ - æ–‡ä»¶æœç´¢å’Œç½‘ç»œæœç´¢
	 * @param {string} query - ç”¨æˆ·æŸ¥è¯¢
	 * @param {string} vectorStoreId - Vector Store ID
	 * @param {string} previousResponseId - å‰ä¸€ä¸ªå“åº” IDï¼ˆç”¨äºå¯¹è¯ä¸Šä¸‹æ–‡ï¼‰
	 * @returns {Promise<Object>} æŸ¥è¯¢ç»“æœ
	 */
	async query(query, vectorStoreId, previousResponseId = null) {
		try {
			Logger.info(`[æ–¹æ¡ˆ1] ä½¿ç”¨OpenAIæœ€ä¾¿å®œçš„æ¨¡å‹: ${OPENAI_MODELS.CHEAPEST}`);
			Logger.info(`æŸ¥è¯¢: ${query}`);

			// å¹¶è¡Œæ‰§è¡Œæ–‡ä»¶æœç´¢å’Œç½‘ç»œæœç´¢
			const [fileResponse, webResponse] = await Promise.all([
				this.fileSearch(query, vectorStoreId, previousResponseId),
				this.webSearch(query),
			]);

			// è®¡ç®—æ€» token ä½¿ç”¨é‡
			const totalInputTokens =
				fileResponse.usage.input_tokens + webResponse.usage.input_tokens;
			const totalOutputTokens =
				fileResponse.usage.output_tokens + webResponse.usage.output_tokens;

			// è®¡ç®—æˆæœ¬
			const modelCost = MODEL_COSTS[OPENAI_MODELS.CHEAPEST];
			const inputCost = (totalInputTokens / 1000000) * 0.15;
			const outputCost = (totalOutputTokens / 1000000) * 0.6;
			const totalCost = inputCost + outputCost;

			// ä½¿ç”¨Loggerè®°å½•æˆæœ¬
			Logger.cost(
				OPENAI_MODELS.CHEAPEST,
				{
					input_tokens: totalInputTokens,
					output_tokens: totalOutputTokens,
					total_tokens: totalInputTokens + totalOutputTokens,
				},
				totalCost
			);

			return {
				success: true,
				fileAnswer: fileResponse.output_text,
				webAnswer: webResponse.output_text,
				fileResponseId: fileResponse.id,
				webResponseId: webResponse.id,
				model: OPENAI_MODELS.CHEAPEST,
				usage: {
					input_tokens: totalInputTokens,
					output_tokens: totalOutputTokens,
					total_tokens: totalInputTokens + totalOutputTokens,
					estimated_cost: totalCost,
				},
				timestamp: new Date().toISOString(),
			};
		} catch (error) {
			console.error('âŒ æŸ¥è¯¢å¤±è´¥:', error);
			throw ErrorHandler.handle(error, {
				operation: 'query',
				query,
				vectorStoreId,
			});
		}
	}

	/**
	 * æ–‡ä»¶æœç´¢ - ä½¿ç”¨ file_search å·¥å…·
	 * @param {string} query - ç”¨æˆ·æŸ¥è¯¢
	 * @param {string} vectorStoreId - Vector Store ID
	 * @param {string} previousResponseId - å‰ä¸€ä¸ªå“åº” ID
	 * @returns {Promise<Object>} æ–‡ä»¶æœç´¢ç»“æœ
	 */
	async fileSearch(query, vectorStoreId, previousResponseId = null) {
		try {
			console.log(`ğŸ” æ‰§è¡Œæ–‡ä»¶æœç´¢...`);

			const requestConfig = {
				model: OPENAI_MODELS.CHEAPEST, // gpt-4o-mini
				input: query,
				tools: [
					{
						type: 'file_search',
						vector_store_ids: [vectorStoreId],
					},
				],
				store: true, // å­˜å‚¨å“åº”ä»¥ä¾¿åç»­ä½¿ç”¨
			};

			// å¦‚æœæœ‰å‰ä¸€ä¸ªå“åº” IDï¼Œæ·»åŠ åˆ°é…ç½®ä¸­ä»¥ç»´æŠ¤å¯¹è¯ä¸Šä¸‹æ–‡
			if (previousResponseId) {
				requestConfig.previous_response_id = previousResponseId;
			}

			const response = await this.client.responses.create(requestConfig);

			console.log(`âœ… æ–‡ä»¶æœç´¢å®Œæˆ`);

			return response;
		} catch (error) {
			console.error('âŒ æ–‡ä»¶æœç´¢å¤±è´¥:', error);
			throw error;
		}
	}

	/**
	 * ç½‘ç»œæœç´¢ - ä½¿ç”¨ OpenAI å†…ç½®çš„ web_search_preview å·¥å…·
	 * @param {string} query - ç”¨æˆ·æŸ¥è¯¢
	 * @returns {Promise<Object>} ç½‘ç»œæœç´¢ç»“æœ
	 */
	async webSearch(query) {
		try {
			console.log(`ğŸŒ æ‰§è¡Œç½‘ç»œæœç´¢...`);

			const response = await this.client.responses.create({
				model: OPENAI_MODELS.CHEAPEST, // gpt-4o-mini
				input: query,
				tools: [
					{
						type: 'web_search_preview',
					},
				],
			});

			console.log(`âœ… ç½‘ç»œæœç´¢å®Œæˆ`);

			return response;
		} catch (error) {
			console.error('âŒ ç½‘ç»œæœç´¢å¤±è´¥:', error);
			throw error;
		}
	}

	/**
	 * ä»…æ–‡ä»¶æœç´¢ï¼ˆä¸è¿›è¡Œç½‘ç»œæœç´¢ï¼‰
	 * @param {string} query - ç”¨æˆ·æŸ¥è¯¢
	 * @param {string} vectorStoreId - Vector Store ID
	 * @param {string} previousResponseId - å‰ä¸€ä¸ªå“åº” ID
	 * @returns {Promise<Object>} æ–‡ä»¶æœç´¢ç»“æœ
	 */
	async fileSearchOnly(query, vectorStoreId, previousResponseId = null) {
		try {
			console.log(
				`ğŸ’° [æ–¹æ¡ˆ1] ä½¿ç”¨OpenAIæœ€ä¾¿å®œçš„æ¨¡å‹: ${OPENAI_MODELS.CHEAPEST}`
			);
			console.log(`ğŸ“ æŸ¥è¯¢ï¼ˆä»…æ–‡ä»¶æœç´¢ï¼‰: ${query}`);

			const response = await this.fileSearch(
				query,
				vectorStoreId,
				previousResponseId
			);

			// è®¡ç®—æˆæœ¬
			const inputCost = (response.usage.input_tokens / 1000000) * 0.15;
			const outputCost = (response.usage.output_tokens / 1000000) * 0.6;
			const totalCost = inputCost + outputCost;

			console.log(`ğŸ“Š Tokenä½¿ç”¨ç»Ÿè®¡:`);
			console.log(
				`   è¾“å…¥: ${
					response.usage.input_tokens
				} tokens (çº¦ $${inputCost.toFixed(6)})`
			);
			console.log(
				`   è¾“å‡º: ${
					response.usage.output_tokens
				} tokens (çº¦ $${outputCost.toFixed(6)})`
			);
			console.log(`   æ€»æˆæœ¬: çº¦ $${totalCost.toFixed(6)}`);

			return {
				success: true,
				answer: response.output_text,
				responseId: response.id,
				model: OPENAI_MODELS.CHEAPEST,
				usage: {
					input_tokens: response.usage.input_tokens,
					output_tokens: response.usage.output_tokens,
					total_tokens:
						response.usage.input_tokens + response.usage.output_tokens,
					estimated_cost: totalCost,
				},
				timestamp: new Date().toISOString(),
			};
		} catch (error) {
			console.error('âŒ æ–‡ä»¶æœç´¢å¤±è´¥:', error);
			throw ErrorHandler.handle(error, {
				operation: 'fileSearchOnly',
				query,
				vectorStoreId,
			});
		}
	}

	/**
	 * è·å–å“åº”è¯¦æƒ…
	 * @param {string} responseId - å“åº” ID
	 * @returns {Promise<Object>} å“åº”è¯¦æƒ…
	 */
	async getResponse(responseId) {
		try {
			const response = await this.client.responses.retrieve(responseId);
			return {
				success: true,
				response: response,
			};
		} catch (error) {
			throw ErrorHandler.handle(error, {
				operation: 'getResponse',
				responseId,
			});
		}
	}
}
